"""
FIXED EVOLUTIONARY STRATEGY PAPER TRADING V2 - THREE TIMEFRAME SPECIALISTS
‚úÖ FIXED: safe_vary function with guaranteed positive scale
‚úÖ FIXED: Agents now generate trades from Generation 0
‚úÖ FIXED: Real-time progress logging
‚úÖ FIXED: Market simulation with realistic volatility
"""

import asyncio
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict
from collections import deque
import json
import logging
import pickle
import os

logger = logging.getLogger(__name__)


@dataclass
class AgentDNA:
    """Genetic encoding with TIMEFRAME specialization"""
    agent_id: int
    generation: int
    
    # ‚≠ê TIMEFRAME TYPE
    timeframe: str  # 'short_term', 'mid_term', 'long_term'
    
    # Risk Parameters
    min_confidence: float
    min_win_prob: float
    volatility_z_threshold: float
    position_size_base: float
    risk_reward_threshold: float
    expected_value_threshold: float
    
    # Exit Strategy Genes
    stop_loss_distance: float
    take_profit_distance: float
    trailing_stop_activation: float
    min_holding_minutes: float
    max_holding_hours: float
    
    # Behavioral Genes
    aggression: float
    patience: float
    contrarian_bias: float
    loss_aversion: float
    
    # Specialization
    asset_preference: str
    regime_preference: str
    
    # Performance Tracking
    total_trades: int = 0
    winning_trades: int = 0
    total_pnl: float = 0.0
    sharpe_ratio: float = 0.0
    fitness_score: float = 0.0
    avg_holding_time: float = 0.0
    regime_performance: Dict[str, Dict] = None
    
    # Ancestry
    parent_ids: List[int] = None
    mutations_count: int = 0
    
    def __post_init__(self):
        if self.regime_performance is None:
            self.regime_performance = {}
        if self.parent_ids is None:
            self.parent_ids = []


@dataclass
class EvolutionaryTrade:
    """Trade generated by evolutionary agent"""
    agent_id: int
    agent_dna: AgentDNA
    asset: str
    action: str
    entry_price: float
    entry_time: datetime
    position_size: float
    stop_loss: float
    take_profit: float
    
    # Live tracking
    current_price: float
    pnl: float
    pnl_pct: float
    status: str
    close_reason: str
    close_time: Optional[datetime]
    
    # Context
    market_regime: str
    confidence_used: float
    win_prob_used: float
    
    # Learning metrics
    max_favorable_move: float = 0.0
    max_adverse_move: float = 0.0
    realized_holding_hours: float = 0.0
    market_volatility: float = 0.0
    trend_strength: float = 0.0


class EvolutionaryAgent:
    """Single trading agent with genetic strategy"""
    
    def __init__(self, dna: AgentDNA, initial_balance: float = 1000.0):
        self.dna = dna
        self.balance = initial_balance
        self.initial_balance = initial_balance
        self.active_trades: List[EvolutionaryTrade] = []
        self.trade_history: List[EvolutionaryTrade] = []
        self.last_trade_time = None
        

    def should_trade(self, market_data: Dict, current_regime: str, current_time: datetime) -> Tuple[bool, float]:
        """‚úÖ FIXED: Much more aggressive - all timeframes trade from Gen 0"""
        
        # Specialization check
        if self.dna.asset_preference != 'ALL' and market_data['asset'] != self.dna.asset_preference:
            return False, 0.0
        
        if self.dna.regime_preference != 'ALL' and current_regime != self.dna.regime_preference:
            return False, 0.0
        
        # Already have position?
        if any(t.asset == market_data['asset'] and t.status == 'open' for t in self.active_trades):
            return False, 0.0
        
        # ‚≠ê TIMEFRAME-SPECIFIC rate limiting (MUCH MORE AGGRESSIVE)
        if self.last_trade_time:
            if self.dna.timeframe == 'short_term':
                cooldown_minutes = 1.0 + (self.dna.patience * 4.0)  # 1-5 min (was 2.5-10)
            elif self.dna.timeframe == 'mid_term':
                cooldown_minutes = 5.0 + (self.dna.patience * 20.0)  # 5-25 min (was 15-120)
            else:  # long_term
                cooldown_minutes = 10.0 + (self.dna.patience * 30.0)  # 10-40 min (was 30-180)
            
            # ‚úÖ SUPER AGGRESSIVE for first 5 generations
            if self.dna.generation < 5:
                cooldown_minutes *= 0.1  # 10% of normal - VERY aggressive
            
            time_since = (current_time - self.last_trade_time).total_seconds() / 60
            if time_since < cooldown_minutes:
                return False, 0.0
        
        # ‚úÖ MUCH HIGHER base probability (was 0.3-0.9, now 0.5-0.95)
        base_trade_prob = 0.5 + (self.dna.aggression * 0.45)
        
        # Adjust based on market conditions
        rsi = market_data.get('rsi', 50)
        
        if self.dna.contrarian_bias < 0:
            if rsi > 70 or rsi < 30:
                base_trade_prob *= 1.5
        elif self.dna.contrarian_bias > 0:
            if 40 < rsi < 60:
                base_trade_prob *= 0.5
        
        if market_data.get('volatility', 0) > 0.05:
            if self.dna.volatility_z_threshold > 3.5:
                base_trade_prob *= 1.2
            else:
                base_trade_prob *= 0.7
        
        # ‚úÖ MASSIVE boost for early generations (first 5)
        if self.dna.generation < 5:
            base_trade_prob = min(base_trade_prob * 2.0, 0.98)  # 2x boost, cap at 98%
        
        # ‚úÖ ADDITIONAL: Timeframe-specific boosts
        if self.dna.timeframe == 'mid_term':
            base_trade_prob *= 1.3  # 30% boost for mid-term
        elif self.dna.timeframe == 'long_term':
            base_trade_prob *= 1.5  # 50% boost for long-term
        
        # Cap at 98%
        base_trade_prob = min(base_trade_prob, 0.98)
        
        trade_decision = np.random.random() < base_trade_prob
        confidence = base_trade_prob * 100
        
        return trade_decision, confidence
    
    def generate_trade_params(self, market_data: Dict, confidence: float) -> Dict:
        """Generate adaptive trade parameters based on DNA, volatility, and confidence"""
        
        rsi = market_data.get('rsi', 50)
        trend = market_data.get('trend_direction', 0)
        volatility = market_data.get('volatility', 0.02)  # 2% default if not provided
        
        # üéØ 1. Determine action based on DNA bias, RSI, and trend
        if self.dna.contrarian_bias < -0.2:
            if rsi > 70:
                action = 'SELL'
            elif rsi < 30:
                action = 'BUY'
            else:
                action = 'BUY' if np.random.random() > 0.5 else 'SELL'
        else:
            if trend > 0.1:
                action = 'BUY'
            elif trend < -0.1:
                action = 'SELL'
            else:
                action = 'BUY' if np.random.random() > 0.5 else 'SELL'
        
        # üí∞ 2. Position sizing (confidence-weighted, capped at 30% balance)
        position_size = self.balance * self.dna.position_size_base * (confidence / 100)
        position_size = min(position_size, self.balance * 0.30)
        
        current_price = market_data['price']
        
        # ‚öñÔ∏è 3. Adaptive stop-loss and take-profit distances
        # Scale distances with volatility and agent DNA
        base_stop = max(0.003, volatility * 0.8)  # never tighter than 0.3%
        base_take = base_stop * 1.8               # R:R ~ 1 : 1.8
        
        # Confidence amplifies distances slightly (higher confidence ‚Üí wider TP)
        stop_loss_dist = base_stop * (1.0 - (confidence / 200))
        take_profit_dist = base_take * (1.0 + (confidence / 300))
        
        # 4. Compute prices
        if action == 'BUY':
            stop_loss = current_price * (1 - stop_loss_dist)
            take_profit = current_price * (1 + take_profit_dist)
        else:
            stop_loss = current_price * (1 + stop_loss_dist)
            take_profit = current_price * (1 - take_profit_dist)
        
        return {
            'action': action,
            'position_size': position_size,
            'stop_loss': stop_loss,
            'take_profit': take_profit,
            'confidence': confidence
        }

    
    def update_fitness(self):
        """Calculate fitness score"""
        if not self.trade_history:
            self.dna.fitness_score = 0.0
            return
        
        # Win rate (30%)
        win_rate = self.dna.winning_trades / self.dna.total_trades if self.dna.total_trades > 0 else 0
        win_rate_score = win_rate * 30
        
        # ROI (40%)
        roi = (self.balance / self.initial_balance - 1) * 100
        pnl_score = np.clip(roi, -50, 100) * 0.4
        
        # Sharpe (20%)
        if self.dna.total_trades >= 5:
            returns = [t.pnl_pct for t in self.trade_history]
            sharpe = (np.mean(returns) / np.std(returns)) if np.std(returns) > 0 else 0
            self.dna.sharpe_ratio = sharpe
            sharpe_score = np.clip(sharpe, -2, 4) * 5
        else:
            sharpe_score = 0
        
        # Trade frequency (10%)
        if self.trade_history:
            trades_per_hour = self.dna.total_trades / max(1, (datetime.now() - self.trade_history[0].entry_time).total_seconds() / 3600)
            
            if self.dna.timeframe == 'short_term':
                ideal_frequency = 2.0
            elif self.dna.timeframe == 'mid_term':
                ideal_frequency = 0.25
            else:
                ideal_frequency = 0.1
            
            frequency_score = 10 - abs(trades_per_hour - ideal_frequency) * 5
            frequency_score = max(0, frequency_score)
        else:
            frequency_score = 0
        
        # Calculate average holding time
        if self.trade_history:
            self.dna.avg_holding_time = np.mean([t.realized_holding_hours for t in self.trade_history])
        
        self.dna.fitness_score = win_rate_score + pnl_score + sharpe_score + frequency_score


class EvolutionaryPaperTradingV2:
    """Enhanced evolutionary system with THREE TIMEFRAME SPECIALISTS"""
    
    def __init__(self, initial_balance: float = 1000.0):
        self.initial_balance = initial_balance
        self.generation = 0
        self.agents: List[EvolutionaryAgent] = []
        self.all_trades: List[EvolutionaryTrade] = []
        
        # ‚è∞ ADDED: Simulated time for accelerated testing
        self.simulated_time = datetime.now()
        
        # Market simulation with REALISTIC volatility
        self.assets = ['BTC', 'ETH', 'SOL', 'BNB', 'XRP']
        self.base_prices = {'BTC': 45000, 'ETH': 2500, 'SOL': 100, 'BNB': 300, 'XRP': 0.5}
        self.current_prices = self.base_prices.copy()
        
        # Market state for realistic simulation
        self.market_momentum = {asset: 0.0 for asset in self.assets}
        self.market_volatility = {asset: 0.02 for asset in self.assets}
        
        # Population
        self.population_size = 90
        self.agents_per_timeframe = 30
        self.elite_size = 9
        self.mutation_rate = 0.15
        
        logger.info("üß¨ EVOLUTIONARY PAPER TRADING V2 - THREE TIMEFRAME SPECIALISTS")
        logger.info(f"   Total Population: {self.population_size}")
        logger.info(f"   Short-Term (5min-3hr): {self.agents_per_timeframe} agents")
        logger.info(f"   Mid-Term (4hr-3days): {self.agents_per_timeframe} agents")
        logger.info(f"   Long-Term (1wk-1month): {self.agents_per_timeframe} agents")
    
    def initialize_population(self):
        """Create population with THREE TIMEFRAME TYPES"""
        logger.info("\nüå± Creating Generation 0 with THREE TIMEFRAMES...")
        
        agent_id = 0
        
        # SHORT-TERM (5min-3hr): 30 agents
        logger.info("\n‚ö° SHORT-TERM SPECIALISTS (5min-3hr):")
        short_archetypes = self._get_short_term_archetypes()
        
        for asset in self.assets:
            for archetype_name, params in short_archetypes.items():
                dna = self._create_dna(agent_id, params, timeframe='short_term', asset_preference=asset)
                agent = EvolutionaryAgent(dna, self.initial_balance)
                self.agents.append(agent)
                logger.info(f"   Agent {agent_id}: {archetype_name} ({asset}) - {dna.min_holding_minutes:.0f}min-{dna.max_holding_hours:.1f}hr")
                agent_id += 1
        
        # MID-TERM (4hr-3days): 30 agents
        logger.info("\nüìä MID-TERM SPECIALISTS (4hr-3days):")
        mid_archetypes = self._get_mid_term_archetypes()
        
        for asset in self.assets:
            for archetype_name, params in mid_archetypes.items():
                dna = self._create_dna(agent_id, params, timeframe='mid_term', asset_preference=asset)
                agent = EvolutionaryAgent(dna, self.initial_balance)
                self.agents.append(agent)
                logger.info(f"   Agent {agent_id}: {archetype_name} ({asset}) - {dna.min_holding_minutes/60:.0f}hr-{dna.max_holding_hours:.0f}hr")
                agent_id += 1
        
        # LONG-TERM (1wk-1month): 30 agents
        logger.info("\nüìà LONG-TERM SPECIALISTS (1wk-1month):")
        long_archetypes = self._get_long_term_archetypes()
        
        for asset in self.assets:
            for archetype_name, params in long_archetypes.items():
                dna = self._create_dna(agent_id, params, timeframe='long_term', asset_preference=asset)
                agent = EvolutionaryAgent(dna, self.initial_balance)
                self.agents.append(agent)
                logger.info(f"   Agent {agent_id}: {archetype_name} ({asset}) - {dna.min_holding_minutes/60:.0f}hr-{dna.max_holding_hours:.0f}hr")
                agent_id += 1
        
        logger.info(f"\n‚úÖ Created {len(self.agents)} agents across 3 timeframes")
    
    def _get_short_term_archetypes(self) -> Dict:
        """Short-term archetypes"""
        return {
            'aggressive_scalper': {
                'aggression': 0.9, 'patience': 0.1,
                'position_size_base': 0.25,
                'min_holding_minutes': 5, 'max_holding_hours': 0.5,
                'stop_loss_distance': 0.005, 'take_profit_distance': 0.010,
                'volatility_z_threshold': 4.0, 'expected_value_threshold': 0.005,
                'min_confidence': 45.0, 'min_win_prob': 0.40
            },
            'momentum_scalper': {
                'aggression': 0.7, 'patience': 0.3,
                'position_size_base': 0.20,
                'min_holding_minutes': 15, 'max_holding_hours': 1.5,
                'stop_loss_distance': 0.010, 'take_profit_distance': 0.020,
                'volatility_z_threshold': 3.5, 'expected_value_threshold': 0.010,
                'min_confidence': 50.0, 'min_win_prob': 0.45
            },
            'range_scalper': {
                'contrarian_bias': -0.3, 'patience': 0.5,
                'position_size_base': 0.18,
                'min_holding_minutes': 30, 'max_holding_hours': 3.0,
                'stop_loss_distance': 0.015, 'take_profit_distance': 0.030,
                'volatility_z_threshold': 3.0, 'expected_value_threshold': 0.015,
                'min_confidence': 55.0, 'min_win_prob': 0.50
            }
        }
    
    def _get_mid_term_archetypes(self) -> Dict:
        """Mid-term archetypes"""
        return {
            'swing_trader': {
                'patience': 0.7, 'aggression': 0.4,
                'position_size_base': 0.20,
                'min_holding_minutes': 240, 'max_holding_hours': 24.0,
                'stop_loss_distance': 0.020, 'take_profit_distance': 0.050,
                'volatility_z_threshold': 3.0, 'expected_value_threshold': 0.015,
                'min_confidence': 55.0, 'min_win_prob': 0.50
            },
            'breakout_trader': {
                'aggression': 0.6, 'patience': 0.5,
                'position_size_base': 0.22,
                'min_holding_minutes': 480, 'max_holding_hours': 48.0,
                'stop_loss_distance': 0.025, 'take_profit_distance': 0.070,
                'volatility_z_threshold': 2.5, 'expected_value_threshold': 0.018,
                'min_confidence': 60.0, 'min_win_prob': 0.52
            },
            'mean_reversion': {
                'contrarian_bias': -0.4, 'patience': 0.8,
                'position_size_base': 0.18,
                'min_holding_minutes': 720, 'max_holding_hours': 72.0,
                'stop_loss_distance': 0.030, 'take_profit_distance': 0.060,
                'volatility_z_threshold': 2.8, 'expected_value_threshold': 0.020,
                'min_confidence': 58.0, 'min_win_prob': 0.51
            }
        }
    
    def _get_long_term_archetypes(self) -> Dict:
        """Long-term archetypes"""
        return {
            'trend_follower': {
                'patience': 0.9, 'aggression': 0.2,
                'position_size_base': 0.15,
                'min_holding_minutes': 1440, 'max_holding_hours': 168.0,
                'stop_loss_distance': 0.040, 'take_profit_distance': 0.100,
                'volatility_z_threshold': 2.5, 'expected_value_threshold': 0.020,
                'min_confidence': 60.0, 'min_win_prob': 0.55
            },
            'position_builder': {
                'patience': 0.95, 'aggression': 0.15,
                'position_size_base': 0.12,
                'min_holding_minutes': 2880, 'max_holding_hours': 240.0,
                'stop_loss_distance': 0.050, 'take_profit_distance': 0.120,
                'volatility_z_threshold': 2.2, 'expected_value_threshold': 0.022,
                'min_confidence': 62.0, 'min_win_prob': 0.56
            },
            'macro_trader': {
                'patience': 0.98, 'aggression': 0.1,
                'position_size_base': 0.10,
                'min_holding_minutes': 4320, 'max_holding_hours': 336.0,
                'stop_loss_distance': 0.060, 'take_profit_distance': 0.150,
                'volatility_z_threshold': 2.0, 'expected_value_threshold': 0.025,
                'min_confidence': 65.0, 'min_win_prob': 0.58
            }
        }
    
    def _create_dna(self, agent_id: int, base_params: Dict, 
                    timeframe: str = 'mid_term',
                    asset_preference: str = 'ALL') -> AgentDNA:
        """‚úÖ FIXED: Create DNA with guaranteed positive variance"""
        
        def safe_vary(value, min_val, max_val, variation_pct=0.15):
            """‚úÖ FIXED: Guaranteed positive scale with better numerical stability"""
            # Ensure value is within bounds first
            value = np.clip(value, min_val, max_val)
            
            # Calculate range-based scale (always positive)
            value_range = max_val - min_val
            base_scale = value_range * variation_pct  # Use range instead of value
            
            # Minimum scale is 1% of range (prevents zero)
            min_scale = value_range * 0.01
            scale = max(base_scale, min_scale)
            
            # Generate variation
            variation = np.random.normal(0, scale)
            varied = value + variation
            
            # Clip to bounds
            return float(np.clip(varied, min_val, max_val))
        
        # TIMEFRAME-SPECIFIC ranges
        if timeframe == 'short_term':
            conf_range = (45.0, 70.0)
            prob_range = (0.40, 0.60)
            stop_range = (0.005, 0.025)
            tp_range = (0.010, 0.050)
            vol_range = (2.5, 4.0)
            ev_range = (0.005, 0.020)
            min_hold_range = (5, 30)
            max_hold_range = (0.5, 4.0)
        elif timeframe == 'mid_term':
            conf_range = (50.0, 75.0)
            prob_range = (0.45, 0.65)
            stop_range = (0.015, 0.040)
            tp_range = (0.030, 0.100)
            vol_range = (2.0, 3.5)
            ev_range = (0.010, 0.025)
            min_hold_range = (240, 720)
            max_hold_range = (4.0, 24.0)
        else:  # long_term
            conf_range = (55.0, 80.0)
            prob_range = (0.50, 0.70)
            stop_range = (0.025, 0.080)
            tp_range = (0.050, 0.200)
            vol_range = (2.0, 3.0)
            ev_range = (0.015, 0.030)
            min_hold_range = (1440, 4320)
            max_hold_range = (24.0, 168.0)
        
        return AgentDNA(
            agent_id=agent_id,
            generation=self.generation,
            timeframe=timeframe,
            min_confidence=safe_vary(base_params.get('min_confidence', sum(conf_range)/2), *conf_range),
            min_win_prob=safe_vary(base_params.get('min_win_prob', sum(prob_range)/2), *prob_range),
            volatility_z_threshold=safe_vary(base_params.get('volatility_z_threshold', sum(vol_range)/2), *vol_range),
            position_size_base=safe_vary(base_params.get('position_size_base', 0.20), 0.10, 0.35),
            risk_reward_threshold=safe_vary(base_params.get('risk_reward_threshold', 2.5), 1.5, 4.0),
            expected_value_threshold=safe_vary(base_params.get('expected_value_threshold', sum(ev_range)/2), *ev_range),
            stop_loss_distance=safe_vary(base_params.get('stop_loss_distance', sum(stop_range)/2), *stop_range),
            take_profit_distance=safe_vary(base_params.get('take_profit_distance', sum(tp_range)/2), *tp_range),
            trailing_stop_activation=safe_vary(base_params.get('trailing_stop_activation', 0.03), 0.01, 0.10),
            min_holding_minutes=safe_vary(base_params.get('min_holding_minutes', sum(min_hold_range)/2), *min_hold_range),
            max_holding_hours=safe_vary(base_params.get('max_holding_hours', sum(max_hold_range)/2), *max_hold_range),
            aggression=safe_vary(base_params.get('aggression', 0.5), 0.0, 1.0),
            patience=safe_vary(base_params.get('patience', 0.5), 0.0, 1.0),
            contrarian_bias=safe_vary(base_params.get('contrarian_bias', 0.0), -0.5, 0.5),
            loss_aversion=safe_vary(base_params.get('loss_aversion', 1.0), 0.5, 2.0),
            asset_preference=asset_preference,
            regime_preference='ALL',
            parent_ids=[]
        )
    
    async def run_evolution_cycle(self, cycles_per_generation: int = 100):
        """Run one generation with REAL-TIME progress logging"""
        logger.info(f"\nüß¨ GENERATION {self.generation}")
        logger.info("="*60)
        
        trades_this_gen = 0
        
        for cycle in range(cycles_per_generation):
            await self._simulate_market_cycle()
            
            # ‚úÖ ADDED: Real-time progress every 10 cycles
            if (cycle + 1) % 10 == 0:
                new_trades = len(self.all_trades) - trades_this_gen
                if new_trades > 0:
                    logger.info(f"   Cycle {cycle + 1}/{cycles_per_generation}: {new_trades} new trades")
                    trades_this_gen = len(self.all_trades)
        
        for agent in self.agents:
            agent.update_fitness()
        
        self._log_generation_stats()
        self.log_training_progress()
        self._evolve_population()
        
        self.generation += 1
    
    async def _simulate_market_cycle(self):
        """‚úÖ IMPROVED: More realistic market simulation with accelerated time"""
        # ‚è∞ SIMULATE TIME PASSING - Each cycle = 5 minutes of simulated time
        self.simulated_time = getattr(self, 'simulated_time', datetime.now())
        self.simulated_time += timedelta(minutes=5)  # Advance 5 minutes per cycle
        
        # Update prices with momentum and mean reversion
        for asset in self.assets:
            # Momentum component
            momentum = self.market_momentum[asset]
            momentum_change = np.random.normal(0, 0.0005)
            self.market_momentum[asset] = np.clip(momentum + momentum_change, -0.01, 0.01)
            
            # Random shock
            shock = np.random.normal(0, self.market_volatility[asset])
            
            # Price update
            price_change = momentum + shock
            self.current_prices[asset] *= (1 + price_change)
            
            # Update volatility
            self.market_volatility[asset] = abs(price_change) * 0.3 + self.market_volatility[asset] * 0.7
        
        regime = self._detect_regime()
        
        for agent in self.agents:
            await self._manage_agent_trades(agent)
            
            for asset in self.assets:
                market_data = self._get_market_data(asset)
                should_trade, confidence = agent.should_trade(market_data, regime, self.simulated_time)  # ‚úÖ Pass simulated time
                
                if should_trade:
                    trade_params = agent.generate_trade_params(market_data, confidence)
                    await self._execute_agent_trade(agent, asset, trade_params, market_data, regime)
    
    def _get_market_data(self, asset: str) -> Dict:
        """Generate market data"""
        price = self.current_prices[asset]
        base_price = self.base_prices[asset]
        
        rsi = np.clip(50 + np.random.normal(0, 15), 20, 80)
        trend_direction = (price - base_price) / base_price
        volatility = self.market_volatility[asset]
        
        return {
            'asset': asset,
            'price': price,
            'rsi': rsi,
            'trend_direction': trend_direction,
            'volatility': volatility
        }
    
    def _detect_regime(self) -> str:
        """Detect market regime"""
        total_movement = sum(abs((price - base) / base) for price, base in zip(self.current_prices.values(), self.base_prices.values()))
        avg_movement = total_movement / len(self.assets)
        
        if avg_movement > 0.02:
            return 'high_volatility'
        elif avg_movement < 0.005:
            return 'ranging'
        else:
            total_trend = sum((price - base) / base for price, base in zip(self.current_prices.values(), self.base_prices.values()))
            if total_trend > 0.01:
                return 'bull_strong'
            elif total_trend < -0.01:
                return 'bear_strong'
            else:
                return 'ranging'
    
    async def _execute_agent_trade(self, agent: EvolutionaryAgent, asset: str, 
                                   trade_params: Dict, market_data: Dict, regime: str):
        """Execute trade with simulated time"""
        # ‚úÖ USE SIMULATED TIME instead of real time
        entry_time = self.simulated_time
        
        trade = EvolutionaryTrade(
            agent_id=agent.dna.agent_id,
            agent_dna=agent.dna,
            asset=asset,
            action=trade_params['action'],
            entry_price=market_data['price'],
            entry_time=entry_time,  # ‚úÖ Use simulated time
            position_size=trade_params['position_size'],
            stop_loss=trade_params['stop_loss'],
            take_profit=trade_params['take_profit'],
            current_price=market_data['price'],
            pnl=0.0,
            pnl_pct=0.0,
            status='open',
            close_reason='',
            close_time=None,
            market_regime=regime,
            confidence_used=trade_params['confidence'],
            win_prob_used=agent.dna.min_win_prob,
            market_volatility=market_data['volatility'],
            trend_strength=market_data['trend_direction']
        )
        
        agent.active_trades.append(trade)
        agent.last_trade_time = entry_time  # ‚úÖ Use simulated time
        
        # ‚úÖ ADDED: Real-time trade logging
        logger.info(f"      üîπ Agent {agent.dna.agent_id} ({agent.dna.timeframe}): {trade_params['action']} {asset} @ ${market_data['price']:.4f}")
    
    async def _manage_agent_trades(self, agent: EvolutionaryAgent):
        """‚úÖ FIXED: Manage trades with SIMULATED TIME"""
        for trade in agent.active_trades[:]:
            if trade.status != 'open':
                continue
            
            trade.current_price = self.current_prices[trade.asset]
            
            # Calculate P&L
            if trade.action == 'BUY':
                trade.pnl_pct = (trade.current_price - trade.entry_price) / trade.entry_price * 100
            else:  # SELL
                trade.pnl_pct = (trade.entry_price - trade.current_price) / trade.entry_price * 100
            
            trade.pnl = trade.position_size * (trade.pnl_pct / 100)
            trade.max_favorable_move = max(trade.max_favorable_move, trade.pnl_pct)
            trade.max_adverse_move = min(trade.max_adverse_move, trade.pnl_pct)
            
            should_close = False
            close_reason = ''
            
            # Stop loss
            if (trade.action == 'BUY' and trade.current_price <= trade.stop_loss) or \
               (trade.action == 'SELL' and trade.current_price >= trade.stop_loss):
                should_close = True
                close_reason = 'stop_loss'
            
            # Take profit
            elif (trade.action == 'BUY' and trade.current_price >= trade.take_profit) or \
                 (trade.action == 'SELL' and trade.current_price <= trade.take_profit):
                should_close = True
                close_reason = 'take_profit'
            
            # ‚è∞ FIXED: Use SIMULATED time for time checks
            holding_minutes = (self.simulated_time - trade.entry_time).total_seconds() / 60
            holding_hours = holding_minutes / 60
            
            if holding_minutes < agent.dna.min_holding_minutes:
                continue  # Don't close yet
            
            if holding_hours > agent.dna.max_holding_hours:
                should_close = True
                close_reason = 'time_exit'
            
            # Loss aversion
            if trade.pnl_pct < -agent.dna.loss_aversion * 3:
                should_close = True
                close_reason = 'loss_aversion_exit'
            
            if should_close:
                await self._close_agent_trade(agent, trade, close_reason)
    
    async def _close_agent_trade(self, agent: EvolutionaryAgent, 
                                 trade: EvolutionaryTrade, close_reason: str):
        """‚úÖ FIXED: Close trade with simulated time"""
        trade.status = 'closed'
        trade.close_reason = close_reason
        trade.close_time = self.simulated_time  # ‚úÖ Use simulated time
        trade.realized_holding_hours = (trade.close_time - trade.entry_time).total_seconds() / 3600
        
        agent.balance += trade.pnl
        agent.dna.total_trades += 1
        if trade.pnl > 0:
            agent.dna.winning_trades += 1
        agent.dna.total_pnl += trade.pnl
        
        # Update regime performance
        if trade.market_regime not in agent.dna.regime_performance:
            agent.dna.regime_performance[trade.market_regime] = {'trades': 0, 'wins': 0, 'total_pnl': 0.0}
        
        regime_stats = agent.dna.regime_performance[trade.market_regime]
        regime_stats['trades'] += 1
        if trade.pnl > 0:
            regime_stats['wins'] += 1
        regime_stats['total_pnl'] += trade.pnl
        
        agent.active_trades.remove(trade)
        agent.trade_history.append(trade)
        self.all_trades.append(trade)
        
        # ‚úÖ ADDED: Log trade closure
        logger.info(f"         ‚úÖ Agent {agent.dna.agent_id} closed: {close_reason} | P&L: {trade.pnl_pct:+.2f}% (${trade.pnl:+.2f})")
    
    def _evolve_population(self):
        """Natural selection with TIMEFRAME preservation"""
        self.agents.sort(key=lambda a: a.dna.fitness_score, reverse=True)
        
        # Get top 3 from each timeframe
        short_agents = [a for a in self.agents if a.dna.timeframe == 'short_term']
        mid_agents = [a for a in self.agents if a.dna.timeframe == 'mid_term']
        long_agents = [a for a in self.agents if a.dna.timeframe == 'long_term']
        
        short_elite = short_agents[:3]
        mid_elite = mid_agents[:3]
        long_elite = long_agents[:3]
        
        logger.info("\nüèÜ TOP PERFORMERS BY TIMEFRAME:")
        logger.info("SHORT-TERM:")
        for i, agent in enumerate(short_elite):
            logger.info(f"   #{i+1} Agent {agent.dna.agent_id}: Fitness={agent.dna.fitness_score:.1f}, "
                       f"Trades={agent.dna.total_trades}, Avg Hold={agent.dna.avg_holding_time:.2f}hr")
        
        logger.info("MID-TERM:")
        for i, agent in enumerate(mid_elite):
            logger.info(f"   #{i+1} Agent {agent.dna.agent_id}: Fitness={agent.dna.fitness_score:.1f}, "
                       f"Trades={agent.dna.total_trades}, Avg Hold={agent.dna.avg_holding_time:.2f}hr")
        
        logger.info("LONG-TERM:")
        for i, agent in enumerate(long_elite):
            logger.info(f"   #{i+1} Agent {agent.dna.agent_id}: Fitness={agent.dna.fitness_score:.1f}, "
                       f"Trades={agent.dna.total_trades}, Avg Hold={agent.dna.avg_holding_time:.2f}hr")
        
        # Create next generation
        new_generation = short_elite + mid_elite + long_elite
        
        # Fill with offspring
        while len(new_generation) < self.population_size:
            short_count = len([a for a in new_generation if a.dna.timeframe == 'short_term'])
            mid_count = len([a for a in new_generation if a.dna.timeframe == 'mid_term'])
            long_count = len([a for a in new_generation if a.dna.timeframe == 'long_term'])
            
            if short_count < self.agents_per_timeframe:
                parent1 = self._tournament_selection(short_agents)
                parent2 = self._tournament_selection(short_agents)
            elif mid_count < self.agents_per_timeframe:
                parent1 = self._tournament_selection(mid_agents)
                parent2 = self._tournament_selection(mid_agents)
            else:
                parent1 = self._tournament_selection(long_agents)
                parent2 = self._tournament_selection(long_agents)
            
            child_dna = self._crossover(parent1.dna, parent2.dna)
            child_dna = self._mutate(child_dna)
            child_agent = EvolutionaryAgent(child_dna, self.initial_balance)
            new_generation.append(child_agent)
        
        self.agents = new_generation
        logger.info(f"‚úÖ Generation {self.generation + 1} created")
    
    def _tournament_selection(self, candidates: List[EvolutionaryAgent], size: int = 5) -> EvolutionaryAgent:
        """Tournament selection"""
        tournament = np.random.choice(candidates, min(size, len(candidates)), replace=False)
        return max(tournament, key=lambda a: a.dna.fitness_score)
    
    def _crossover(self, parent1: AgentDNA, parent2: AgentDNA) -> AgentDNA:
        """Crossover (preserves timeframe)"""
        child_id = max(a.dna.agent_id for a in self.agents) + 1
        
        def crossover_gene(gene1, gene2):
            return gene1 if np.random.random() > 0.5 else gene2
        
        return AgentDNA(
            agent_id=child_id,
            generation=self.generation + 1,
            timeframe=parent1.timeframe,
            min_confidence=crossover_gene(parent1.min_confidence, parent2.min_confidence),
            min_win_prob=crossover_gene(parent1.min_win_prob, parent2.min_win_prob),
            volatility_z_threshold=crossover_gene(parent1.volatility_z_threshold, parent2.volatility_z_threshold),
            position_size_base=crossover_gene(parent1.position_size_base, parent2.position_size_base),
            risk_reward_threshold=crossover_gene(parent1.risk_reward_threshold, parent2.risk_reward_threshold),
            expected_value_threshold=crossover_gene(parent1.expected_value_threshold, parent2.expected_value_threshold),
            stop_loss_distance=crossover_gene(parent1.stop_loss_distance, parent2.stop_loss_distance),
            take_profit_distance=crossover_gene(parent1.take_profit_distance, parent2.take_profit_distance),
            trailing_stop_activation=crossover_gene(parent1.trailing_stop_activation, parent2.trailing_stop_activation),
            min_holding_minutes=crossover_gene(parent1.min_holding_minutes, parent2.min_holding_minutes),
            max_holding_hours=crossover_gene(parent1.max_holding_hours, parent2.max_holding_hours),
            aggression=crossover_gene(parent1.aggression, parent2.aggression),
            patience=crossover_gene(parent1.patience, parent2.patience),
            contrarian_bias=crossover_gene(parent1.contrarian_bias, parent2.contrarian_bias),
            loss_aversion=crossover_gene(parent1.loss_aversion, parent2.loss_aversion),
            asset_preference=crossover_gene(parent1.asset_preference, parent2.asset_preference),
            regime_preference=crossover_gene(parent1.regime_preference, parent2.regime_preference),
            parent_ids=[parent1.agent_id, parent2.agent_id]
        )
    
    def _mutate(self, dna: AgentDNA) -> AgentDNA:
        """‚úÖ FIXED: Mutation with guaranteed positive scale"""
        mutated_dna = dna
        mutations = 0
        
        genes = [
            'min_confidence', 'min_win_prob', 'volatility_z_threshold',
            'position_size_base', 'risk_reward_threshold', 'expected_value_threshold',
            'stop_loss_distance', 'take_profit_distance', 'trailing_stop_activation', 
            'min_holding_minutes', 'max_holding_hours',
            'aggression', 'patience', 'contrarian_bias', 'loss_aversion'
        ]
        
        for gene in genes:
            if np.random.random() < self.mutation_rate:
                current_value = getattr(mutated_dna, gene)
                
                # ‚úÖ FIXED: Use range-based mutation scale (always positive)
                if gene in ['min_confidence', 'volatility_z_threshold', 'max_holding_hours']:
                    mutation_strength = 0.3
                elif gene in ['min_win_prob', 'aggression', 'patience', 'loss_aversion']:
                    mutation_strength = 0.2
                else:
                    mutation_strength = 0.15
                
                # Determine range for this gene
                if gene == 'min_confidence':
                    if dna.timeframe == 'short_term':
                        gene_range = (45.0, 70.0)
                    elif dna.timeframe == 'mid_term':
                        gene_range = (50.0, 75.0)
                    else:
                        gene_range = (55.0, 80.0)
                elif gene == 'min_win_prob':
                    if dna.timeframe == 'short_term':
                        gene_range = (0.40, 0.60)
                    elif dna.timeframe == 'mid_term':
                        gene_range = (0.45, 0.65)
                    else:
                        gene_range = (0.50, 0.70)
                elif gene == 'stop_loss_distance':
                    if dna.timeframe == 'short_term':
                        gene_range = (0.005, 0.025)
                    elif dna.timeframe == 'mid_term':
                        gene_range = (0.015, 0.040)
                    else:
                        gene_range = (0.025, 0.080)
                elif gene == 'take_profit_distance':
                    if dna.timeframe == 'short_term':
                        gene_range = (0.010, 0.050)
                    elif dna.timeframe == 'mid_term':
                        gene_range = (0.030, 0.100)
                    else:
                        gene_range = (0.050, 0.200)
                elif gene == 'volatility_z_threshold':
                    if dna.timeframe == 'short_term':
                        gene_range = (2.5, 4.0)
                    elif dna.timeframe == 'mid_term':
                        gene_range = (2.0, 3.5)
                    else:
                        gene_range = (2.0, 3.0)
                elif gene == 'expected_value_threshold':
                    if dna.timeframe == 'short_term':
                        gene_range = (0.005, 0.020)
                    elif dna.timeframe == 'mid_term':
                        gene_range = (0.010, 0.025)
                    else:
                        gene_range = (0.015, 0.030)
                elif gene == 'min_holding_minutes':
                    if dna.timeframe == 'short_term':
                        gene_range = (5, 30)
                    elif dna.timeframe == 'mid_term':
                        gene_range = (240, 720)
                    else:
                        gene_range = (1440, 4320)
                elif gene == 'max_holding_hours':
                    if dna.timeframe == 'short_term':
                        gene_range = (0.5, 4.0)
                    elif dna.timeframe == 'mid_term':
                        gene_range = (4.0, 24.0)
                    else:
                        gene_range = (24.0, 168.0)
                elif gene == 'position_size_base':
                    gene_range = (0.10, 0.35)
                elif gene == 'risk_reward_threshold':
                    gene_range = (1.5, 4.0)
                elif gene == 'trailing_stop_activation':
                    gene_range = (0.01, 0.10)
                elif gene in ['aggression', 'patience']:
                    gene_range = (0.0, 1.0)
                elif gene == 'contrarian_bias':
                    gene_range = (-0.5, 0.5)
                elif gene == 'loss_aversion':
                    gene_range = (0.5, 2.0)
                else:
                    gene_range = (0, 1)
                
                # ‚úÖ FIXED: Range-based scale (always positive)
                range_size = gene_range[1] - gene_range[0]
                scale = range_size * mutation_strength
                scale = max(scale, range_size * 0.01)  # Minimum 1% of range
                
                mutation = np.random.normal(0, scale)
                new_value = current_value + mutation
                new_value = float(np.clip(new_value, gene_range[0], gene_range[1]))
                
                setattr(mutated_dna, gene, new_value)
                mutations += 1
        
        mutated_dna.mutations_count = mutations
        return mutated_dna
    
    def log_training_progress(self):
        """Detailed training progress for Meta-RL bootstrap"""
        if self.generation < 1:
            return
        
        recent_trades = self.all_trades[-100:] if len(self.all_trades) >= 100 else self.all_trades
        
        if not recent_trades:
            return
        
        # Trades per hour
        if len(recent_trades) >= 10:
            time_span = (recent_trades[-1].entry_time - recent_trades[0].entry_time).total_seconds() / 3600
            if time_span > 0:
                trades_per_hour = len(recent_trades) / time_span
            else:
                trades_per_hour = 0
        else:
            trades_per_hour = 0
        
        # Convergence metrics
        top_agents = sorted(self.agents, key=lambda a: a.dna.fitness_score, reverse=True)[:10]
        fitness_variance = np.var([a.dna.fitness_score for a in top_agents])
        
        logger.info("\n" + "="*70)
        logger.info("üìà EVOLUTIONARY TRAINING PROGRESS")
        logger.info("="*70)
        logger.info(f"Generation: {self.generation}")
        logger.info(f"Total Trades Generated: {len(self.all_trades)}")
        logger.info(f"Recent Trade Rate: {trades_per_hour:.1f} trades/hour")
        logger.info(f"Target Rate: 500-800 trades/day (‚âà20-33 trades/hour)")
        logger.info(f"Top 10 Fitness Variance: {fitness_variance:.2f} (lower = more convergence)")
        
        # Distribution
        short_trades = len([t for t in recent_trades if t.agent_dna.timeframe == 'short_term'])
        mid_trades = len([t for t in recent_trades if t.agent_dna.timeframe == 'mid_term'])
        long_trades = len([t for t in recent_trades if t.agent_dna.timeframe == 'long_term'])
        
        logger.info(f"\nTimeframe Distribution (last 100 trades):")
        logger.info(f"   Short-term: {short_trades} ({short_trades/max(1,len(recent_trades))*100:.1f}%)")
        logger.info(f"   Mid-term: {mid_trades} ({mid_trades/max(1,len(recent_trades))*100:.1f}%)")
        logger.info(f"   Long-term: {long_trades} ({long_trades/max(1,len(recent_trades))*100:.1f}%)")
        logger.info("="*70 + "\n")
    
    def _log_generation_stats(self):
        """Log generation statistics by timeframe"""
        if not self.agents:
            return
        
        # Overall stats
        total_trades = sum(a.dna.total_trades for a in self.agents)
        total_wins = sum(a.dna.winning_trades for a in self.agents)
        total_pnl = sum(a.dna.total_pnl for a in self.agents)
        
        # By timeframe
        short_agents = [a for a in self.agents if a.dna.timeframe == 'short_term']
        mid_agents = [a for a in self.agents if a.dna.timeframe == 'mid_term']
        long_agents = [a for a in self.agents if a.dna.timeframe == 'long_term']
        
        short_trades = sum(a.dna.total_trades for a in short_agents)
        short_wins = sum(a.dna.winning_trades for a in short_agents)
        short_pnl = sum(a.dna.total_pnl for a in short_agents)
        
        mid_trades = sum(a.dna.total_trades for a in mid_agents)
        mid_wins = sum(a.dna.winning_trades for a in mid_agents)
        mid_pnl = sum(a.dna.total_pnl for a in mid_agents)
        
        long_trades = sum(a.dna.total_trades for a in long_agents)
        long_wins = sum(a.dna.winning_trades for a in long_agents)
        long_pnl = sum(a.dna.total_pnl for a in long_agents)
        
        logger.info(f"\nüìà GENERATION {self.generation} STATS:")
        logger.info(f"   Total Trades: {total_trades}")
        logger.info(f"   Overall Win Rate: {total_wins/max(1,total_trades)*100:.1f}%")
        logger.info(f"   Total P&L: ${total_pnl:+.2f}")
        
        logger.info(f"\n   SHORT-TERM (5min-3hr):")
        logger.info(f"     Trades: {short_trades}")
        logger.info(f"     Win Rate: {short_wins/max(1,short_trades)*100:.1f}%")
        logger.info(f"     P&L: ${short_pnl:+.2f}")
        
        logger.info(f"\n   MID-TERM (4hr-3days):")
        logger.info(f"     Trades: {mid_trades}")
        logger.info(f"     Win Rate: {mid_wins/max(1,mid_trades)*100:.1f}%")
        logger.info(f"     P&L: ${mid_pnl:+.2f}")
        
        logger.info(f"\n   LONG-TERM (1wk-1month):")
        logger.info(f"     Trades: {long_trades}")
        logger.info(f"     Win Rate: {long_wins/max(1,long_trades)*100:.1f}%")
        logger.info(f"     P&L: ${long_pnl:+.2f}")
    
    def export_training_data_for_meta_rl(self) -> List[Dict]:
        """Export trades for MetaRLV5"""
        training_data = []
        
        for trade in self.all_trades:
            if trade.status != 'closed':
                continue
            
            training_data.append({
                'timestamp': trade.entry_time.isoformat(),
                'asset': trade.asset,
                'action': trade.action,
                'timeframe': trade.agent_dna.timeframe,
                'entry_price': trade.entry_price,
                'exit_price': trade.current_price,
                'pnl': trade.pnl,
                'pnl_pct': trade.pnl_pct,
                'success': trade.pnl > 0,
                'holding_hours': trade.realized_holding_hours,
                'close_reason': trade.close_reason,
                'market_regime': trade.market_regime,
                'market_volatility': trade.market_volatility,
                'trend_strength': trade.trend_strength,
                'parameters': {
                    'timeframe': trade.agent_dna.timeframe,
                    'min_confidence': trade.agent_dna.min_confidence,
                    'min_win_prob': trade.agent_dna.min_win_prob,
                    'volatility_z_threshold': trade.agent_dna.volatility_z_threshold,
                    'expected_value_threshold': trade.agent_dna.expected_value_threshold,
                    'position_size_base': trade.agent_dna.position_size_base,
                    'stop_loss_distance': trade.agent_dna.stop_loss_distance,
                    'take_profit_distance': trade.agent_dna.take_profit_distance,
                    'min_holding_minutes': trade.agent_dna.min_holding_minutes,
                    'max_holding_hours': trade.agent_dna.max_holding_hours,
                    'aggression': trade.agent_dna.aggression,
                    'patience': trade.agent_dna.patience,
                    'contrarian_bias': trade.agent_dna.contrarian_bias,
                    'loss_aversion': trade.agent_dna.loss_aversion
                },
                'max_favorable_move': trade.max_favorable_move,
                'max_adverse_move': trade.max_adverse_move,
                'agent_fitness': trade.agent_dna.fitness_score,
                'confidence_used': trade.confidence_used,
                'win_prob_used': trade.win_prob_used,
                'agent_generation': trade.agent_dna.generation
            })
        
        return training_data
    
    def get_evolutionary_insights(self) -> Dict:
        """Get insights by timeframe"""
        if not self.agents:
            return {}
        
        short_agents = [a for a in self.agents if a.dna.timeframe == 'short_term']
        mid_agents = [a for a in self.agents if a.dna.timeframe == 'mid_term']
        long_agents = [a for a in self.agents if a.dna.timeframe == 'long_term']
        
        short_agents.sort(key=lambda a: a.dna.fitness_score, reverse=True)
        mid_agents.sort(key=lambda a: a.dna.fitness_score, reverse=True)
        long_agents.sort(key=lambda a: a.dna.fitness_score, reverse=True)
        
        return {
            'generation': self.generation,
            'total_trades_generated': len(self.all_trades),
            'population_size': len(self.agents),
            
            'short_term_agents': {
                'count': len(short_agents),
                'top_3': [
                    {
                        'agent_id': agent.dna.agent_id,
                        'fitness': agent.dna.fitness_score,
                        'trades': agent.dna.total_trades,
                        'win_rate': agent.dna.winning_trades / max(1, agent.dna.total_trades) * 100,
                        'avg_holding_time': agent.dna.avg_holding_time,
                        'pnl': agent.dna.total_pnl
                    }
                    for agent in short_agents[:3]
                ]
            },
            
            'mid_term_agents': {
                'count': len(mid_agents),
                'top_3': [
                    {
                        'agent_id': agent.dna.agent_id,
                        'fitness': agent.dna.fitness_score,
                        'trades': agent.dna.total_trades,
                        'win_rate': agent.dna.winning_trades / max(1, agent.dna.total_trades) * 100,
                        'avg_holding_time': agent.dna.avg_holding_time,
                        'pnl': agent.dna.total_pnl
                    }
                    for agent in mid_agents[:3]
                ]
            },
            
            'long_term_agents': {
                'count': len(long_agents),
                'top_3': [
                    {
                        'agent_id': agent.dna.agent_id,
                        'fitness': agent.dna.fitness_score,
                        'trades': agent.dna.total_trades,
                        'win_rate': agent.dna.winning_trades / max(1, agent.dna.total_trades) * 100,
                        'avg_holding_time': agent.dna.avg_holding_time,
                        'pnl': agent.dna.total_pnl
                    }
                    for agent in long_agents[:3]
                ]
            }
        }


# Bootstrap function
async def bootstrap_meta_rl_with_evolution_v2():
    """Bootstrap MetaRLV5 with THREE-TIMEFRAME evolutionary training"""
    from meta_rl_enhanced2 import MetaRLSupervisorV5
    
    meta_rl = MetaRLSupervisorV5(initial_balance=1000.0)
    evolutionary_system = EvolutionaryPaperTradingV2(initial_balance=1000.0)
    evolutionary_system.initialize_population()
    
    logger.info("üöÄ Running THREE-TIMEFRAME evolutionary training...")
    logger.info("   30 Short-term specialists (5min-3hr)")
    logger.info("   30 Mid-term specialists (4hr-3days)")
    logger.info("   30 Long-term specialists (1wk-1month)")
    
    for generation in range(5):
        await evolutionary_system.run_evolution_cycle(cycles_per_generation=50)
        
        # Feed trades to MetaRLV5
        training_data = evolutionary_system.export_training_data_for_meta_rl()
        for trade in training_data:
            meta_rl.record_trade_outcome(
                traded=True,
                action=trade['action'],
                market_regime=trade['market_regime'],
                pnl=trade['pnl'],
                pnl_pct=trade['pnl_pct'],
                success=trade['success'],
                confidence_used=trade['confidence_used'],
                win_prob_used=trade['win_prob_used'],
                parameters_used=trade['parameters'],
                timeframe=trade['timeframe']
            )
        
        logger.info(f"   Generation {generation + 1}: {len(training_data)} trades fed to MetaRLV5")
    
    insights = evolutionary_system.get_evolutionary_insights()
    
    logger.info("\n‚úÖ MetaRLV5 bootstrapped with THREE-TIMEFRAME evolutionary data")
    logger.info(f"   Total Trades: {len(evolutionary_system.all_trades)}")
    logger.info(f"   Short-term: {sum(1 for t in evolutionary_system.all_trades if t.agent_dna.timeframe == 'short_term')}")
    logger.info(f"   Mid-term: {sum(1 for t in evolutionary_system.all_trades if t.agent_dna.timeframe == 'mid_term')}")
    logger.info(f"   Long-term: {sum(1 for t in evolutionary_system.all_trades if t.agent_dna.timeframe == 'long_term')}")
    
    logger.info("\nüèÜ TOP SHORT-TERM STRATEGY:")
    if insights['short_term_agents']['top_3']:
        top = insights['short_term_agents']['top_3'][0]
        logger.info(f"   Win Rate: {top['win_rate']:.1f}%")
        logger.info(f"   Avg Hold: {top['avg_holding_time']:.2f} hours")
        logger.info(f"   P&L: ${top['pnl']:+.2f}")
    
    logger.info("\nüèÜ TOP MID-TERM STRATEGY:")
    if insights['mid_term_agents']['top_3']:
        top = insights['mid_term_agents']['top_3'][0]
        logger.info(f"   Win Rate: {top['win_rate']:.1f}%")
        logger.info(f"   Avg Hold: {top['avg_holding_time']:.2f} hours")
        logger.info(f"   P&L: ${top['pnl']:+.2f}")
    
    logger.info("\nüèÜ TOP LONG-TERM STRATEGY:")
    if insights['long_term_agents']['top_3']:
        top = insights['long_term_agents']['top_3'][0]
        logger.info(f"   Win Rate: {top['win_rate']:.1f}%")
        logger.info(f"   Avg Hold: {top['avg_holding_time']:.2f} hours")
        logger.info(f"   P&L: ${top['pnl']:+.2f}")
    
    return meta_rl, insights


# Test function
async def main():
    """Test the THREE-TIMEFRAME evolutionary system"""
    logging.basicConfig(level=logging.INFO)
    
    system = EvolutionaryPaperTradingV2(initial_balance=1000.0)
    system.initialize_population()
    
    # Run evolution for a few generations
    for generation in range(3):
        await system.run_evolution_cycle(cycles_per_generation=50)
        
        # Display insights
        insights = system.get_evolutionary_insights()
        
        logger.info(f"\nüìä GENERATION {generation + 1} INSIGHTS:")
        logger.info(f"   Total Trades: {insights['total_trades_generated']}")
        
        # Show top performers by timeframe
        for timeframe in ['short_term_agents', 'mid_term_agents', 'long_term_agents']:
            if insights[timeframe]['top_3']:
                top_agent = insights[timeframe]['top_3'][0]
                logger.info(f"   {timeframe.replace('_', ' ').title()}: "
                           f"Agent {top_agent['agent_id']} - "
                           f"Fitness: {top_agent['fitness']:.1f}, "
                           f"Win Rate: {top_agent['win_rate']:.1f}%")
    
    # Export training data
    training_data = system.export_training_data_for_meta_rl()
    logger.info(f"\nüì¶ Exported {len(training_data)} trades for MetaRL training")
    
    # Show final statistics
    system._log_generation_stats()


if __name__ == "__main__":
    asyncio.run(main())